version: "3.8"

services:
  fastapi:
    build:
      context: .
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    container_name: fastapi_app
    ports:
      - "8000:8000"
    depends_on:
      - redis
    volumes:
      - ./credentials.json:/app/credentials.json:ro
      - ./incoming:/app/incoming
    command: python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  redis:
    image: redis:6
    container_name: redis
    ports:
      - "6379:6379"

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: celery_worker
    shm_size: "2gb" # Allows OpenCV/Paddle to process large images
    environment:
      - SPREADSHEET_ID=1u3M6OKKg08A0SA_Sz-hhDn4aVmbbG27Rl8msOKFFxpI
      # Sets the number of worker processes to 1 to reduce resource contention
      # during the heavy model loading phase.
      - C_FORCE_ROOT=true
    depends_on:
      - redis
    volumes:
      - ./credentials.json:/app/credentials.json:ro
      - ./incoming:/app/incoming
    command: python -m celery -A tasks worker --loglevel=info

  whatsapp_listener:
    build:
      context: ./listener
      dockerfile: Dockerfile
    container_name: whatsapp_listener
    depends_on:
      fastapi:
        condition: service_healthy
      redis:
        condition: service_started
    command: node index.js
    stdin_open: true
    tty: true
    volumes:
      - ./listener/auth:/app/auth
      - ./app/qr:/app/qr
      - ./incoming:/app/incoming
